{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h1><center>질문스터디 2주차</center></h1>\n",
    "\n",
    "---\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1) 모집단의 수가 매우 적은 (수십개 이하) 케이스의 경우 어떤 방식으로 예측 모델을 수립할 수 있을까요?\n",
    "\n",
    "A1) \n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2) 베이지안과 프리퀀티스트간의 입장차이를 설명해주실 수 있나요?\n",
    "\n",
    "A2) \n",
    "\n",
    "<h3>조건부확률</h3>\n",
    "\n",
    "- B라는 사건이 일어 났을때 A사건이 일어날 확률. 여기서 B라는 사건이 이미 일어난 상황에서 A가 일어 났다는 것은 결국 A와 B가 동시에 일어났다는 것이다.\n",
    "\n",
    "- P(A|B) = P(A∩B)/P(B) (단, P(B) != 0)\n",
    "\n",
    "[예제1]\n",
    "\n",
    "1~20까지의 숫자가 적혀있는 카드가 있다고 할때,\n",
    "\n",
    "A: 2의 배수가 나오는 사건\n",
    "\n",
    "B: 3의 배수가 나오는 사건\n",
    "\n",
    "이라 하자. 이때, 2의 배수가 나왔을 때 그것이 3의 배수였을 확률은 얼마인가?\n",
    "\n",
    "Answer) P(B|A) = P(B∩A)/P(A) = 6의 배수가 나올 확률 / (10/20) = (3/20) / (10/20) = 3/10 = (6의 배수인 카드) / (2의 배수인 카드)\n",
    "\n",
    " \n",
    "\n",
    "[예제2] \n",
    "\n",
    "||안경|맨눈|\n",
    "|---\n",
    "|남학생|5|7|\n",
    "|여학생|6|4|\n",
    "\n",
    "A: 남학생일 사건\n",
    "\n",
    "B: 안경을 끼고 있는 사건\n",
    "\n",
    "이라 하자. 학생을 뽑았는데, 그 학생일 남학생이 었을때, 그 남학생이 안경을 끼고 있을 확률은?\n",
    "\n",
    "Answer) P(B|A) = P(B교A) / P(A) = (5/22) / (12/22) = 5/12 = (안경을 끼는 남학생의 수) / (전체 남학생의 수)\n",
    "\n",
    " \n",
    "\n",
    "*** 여기서 표본 공간이 주어진 조건으로 바뀌는 것을 볼 수 있다.\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "\n",
    "<h3>베이즈 정리</h3>\n",
    "\n",
    "- 베이즈 정리는 이전의 경험과 현재의 증거를 토대로 어떤 사건의 확률을 추론하는 알고리즘이다. 즉, 사건이 일어날 확률을 토대로 의사결정을 할 경우 그와 관련된 사전 정보를 얼마나 알고 있고 제대로 적용할 수 있는가에 크게 좌우된다.\n",
    "\n",
    "- 양성반응일때 유방암일 확률 = P(암|양성) = P(암∩양성)/P(양성) => P(암∩양성) = P(암|양성)P(양성)\n",
    "\n",
    "  유방암일때 양성반응일 확률 = P(양성|암) = P(양성∩암)/P(암) => P(양성∩암) = P(양성|암)P(암)\n",
    "\n",
    "  따라서, P(암∩양성) = P(암|양성)P(양성) = P(양성|암)P(암) = P(양성∩암)\n",
    "\n",
    "  이 식은 다음과 같은 식으로 변형이 될 수 있다.\n",
    "\n",
    "  P(암|양성) = P(양성|암)P(암)/P(양성)\n",
    "\n",
    " \n",
    "\n",
    "  여기서 P(양성|암) 즉, '유방암일 때 양성반응일 확률'(사전확률)이 90%라 하자. (여기서 P(암|양성)과 착각하지 않도록 하자)\n",
    "\n",
    "  이 뜻은 암일 경우 양성으로 판단될 확률이 90%라는 것이다. 즉, 90프로의 확률로 암을 가진 환자가 양성판정을 받는 다는 것이다.\n",
    "\n",
    "  P(암) 즉, 유방암에 걸린 사람의 비율이 0.01이라 하자.\n",
    "\n",
    "  P(양성)은 (암에 걸린 여성이 양성반응인 확률 즉, P(양성|암)P(암)) + (유방암에 안걸린 여성이 양성반응인 확률 즉, P(양성|N)P(N)) 이므로, 0.9*0.01 + 0.1*0.99 = 0.108\n",
    "\n",
    "  따라서 P(암|양성) = 0.9*0.01/0.108 = 0.083으로 검사에서 양성일 경우 유방암일 확률은 8.3%가 된다.\n",
    "\n",
    " \n",
    "\n",
    "  정확도가 99%로 높아졌다고 하자. 그러면 P(양성|암) = 0.99이고, P(양성) = 0.0198 (0.99*0.01 + 0.01*0.99)이므로, P(암|양성) = 0.99*0.01/0.0198 = 0.5로 50%가 된다. \n",
    "\n",
    " \n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    " \n",
    "<h3>베이지안과 프리퀀티스트 간의 입장 차이</h3>\n",
    "\n",
    "- 확률을 객관적으로 발생하는 현상의 빈도수에 대한 기술로 보느냐 VS 현상에 대한 관찰자의 주관적인 믿음의 체계로 보느냐\n",
    "\n",
    "- fair한 6면 주사위가 하나 있을때, 이 주사위를 던져서 1의 눈이 나올 확률은?\n",
    "\n",
    "    - frequentist\n",
    "    \n",
    "            1/6 (∵ 주사위는 fair하므로 6개의 경우들은 모두 같은 빈도로 발생할 것이다.)\n",
    "\n",
    "    - bayesian\n",
    "\n",
    "        1. 1의 눈이 나올 확률은 0과 1사이의 임의의 값이다. 임의로 1/10이라 간주한다. (사전확률)\n",
    "\n",
    "        2. 이 주사위를 실제로 6000번 던졌더니 그 중 992번이 1이 나왔다. (데이터)\n",
    "\n",
    "        3. 데이터가 있으므로 새로운 데이터를 이용해서 사전확률을 수정한다. 새로운 확률(사후확률)은 992/6000이다.\n",
    "        \n",
    "\n",
    "- frequentist들은 992/6000이 1/6에 매우 근접하므로 이 데이터는 1의 눈이 나올 확률이 1/6이라는 '가설'을 confirm한다고 생각한다. 즉, frequentist들에게는 '참된 확률값'이라는 것이 존재하는 것이다. (여게서 992/6000은 가설을 검증을 통해 얻은 추정치로 간주한다.)\n",
    "\n",
    "  반면 bayesian은 1의 눈이 나올 확률이 어떤 확률분포를 가지고 있다고 생각한다. (6000번중에 1이 한번도 나오지 않을 확률, 1번 나올 확률, ... , 6000번 나올 확률 하는 식오로) 즉, 확률값의 참된 분포 (데이터를 만들어내는 내재적 과정)는 있지만 '참된 확률값'이란 것은 없는 것이다.\n",
    "\n",
    "  따라서 bayesian은 데이터를 얻기 전에 분포에 대한 믿음, 즉, 사전확률분포를 가지고 있다. 그리고 데이터를 얻게 되면 자신들의 과거의 견해를 갱신(update)해서 새로운 믿음(사후확률분포)를 만든다. bayesian들은 갱신과정을 거쳐 믿음을 참된 분포에 근접시킨다.\n",
    "\n",
    "- 병원에 배가 아픈 환자가 왔다고 하자\n",
    "\n",
    "    - frequentist : 그 환자를 직접 검사 하여 source of pain을 찾는다.\n",
    "\n",
    "    - bayesian : 비슷한 증상의 이전 환자의 증상과 결합하여 source of pain을 찾는다.\n",
    "\n",
    "- 결론 : frequentist는 현재의 객관적인 사건으로 판단, bayesian은 과거의 사건이 현재 사건에 영향을 미침\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "[출처 : http://astralworld58.tistory.com/81\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3) 검정력(statistical power)은 무엇일까요?\n",
    "\n",
    "A3)\n",
    "\n",
    "검정력은 간단히 말해, 2종 오류를 범하지 않을 확률이다.<br></br>\n",
    "즉 대립가설이 옳음에도 귀무가설을 기각하지 않는 오류가 2종 오류(β)인데, 이러한 오류를 범하지 않을 확률 1-β를 검정력(power)이라고 한다.\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "그런데, <br></br>\n",
    " \n",
    "\"귀무가설과 대립가설이 모두 단순가설로 주어진 경우에는 제 2종의 오류를 범할 확률을 구할 수 있다.<br></br>\n",
    "그러나 대립가설이 복합가설로 주어지는 경우에는 대립가설의 범위에서 지정된 하나의 모수값에 대해서 구할 수 있다(수리통계학, 212).\"<br></br>\n",
    "\n",
    "그래서 대립가설이 복합가설로 주어지는 경우, 2종 오류에 대한 확률을 다양한 모수값에 대한 함수로 표현한 것을 검정력 함수(power function)라고 한다. <br></br>\n",
    "정확히 말하면 모수 θ에 따라서 2종 오류를 범하지 않을 확률값 1-β를 보여주는 함수이다.<br></br>\n",
    "\n",
    "검정력과 검정력 함수에 대한 정확한 정의는 다음과 같다(수리통계학, 212).<br></br>\n",
    "\n",
    " - (1) 검정법에서 귀무가설 H0를 기각시킬 확률을 모수 θ의 함수로 나타낸 것을 검정력 함수(power function)라고 하며, 이를 수식으로 나타내면 다음과 같다.\n",
    " \n",
    "$$π(θ) - P[H_0를 기각|θ]$$\n",
    " \n",
    " - (2) 대립가설 H1에 속하는 특정 θ에 대한 검정력 함수의 값을 검정력(power)이라 한다.\n",
    "\n",
    "1종 오류의 확률(α)은 특정한 값을 미리 정해서 관리하지만 2종 오류의 확률(β)은 일단 α가 주어지면 대립가설에 따라 자동으로 정해지게 된다.\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<img src=\"https://mblogthumb-phinf.pstatic.net/20150912_129/cto_hwangga_14420399175019YLgp_JPEG/20150912_153719.jpg?type=w2\">\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "위 그림(수리통계학, 211~212, 그림 5.2)은 귀무가설 H0과 대립가설 H1의 분포를 보여준다(분산은 4, n =25).<br></br>\n",
    "X의 표본평균이 정규분포를 따른다고 가정하고 귀무가설 H0는 θ = 0이라는 주장을, 대립가설 H1은 θ = 1이라는 주장을 대표하고 있다.\n",
    "\n",
    "\n",
    "이 그림에서 α = 0.025로 정해졌고(이 말은 1종 오류의 확률을 0.025로 관리한다는 의미이다), 그에 따라 기각역도 결정되었다. <br></br>\n",
    "이 예에서 X의 표본평균이 0.784 이상인 경우 귀무가설은 기각된다.\n",
    "\n",
    "\n",
    "이 경우 귀무가설이 참이지만 귀무가설을 기각하는 결정을 내릴 오류의 확률은 α=0.025이다. <br></br>\n",
    "반면 대립가설이 참임에도 귀무가설을 기각하지 않는 경우, 즉 대립가설을 채택(자주 사용하는 표현은 아니다)하지 않는 경우의 확률이 바로 β=0.2946이다. \n",
    "\n",
    "\n",
    "위 예에서는 표본평균이 0.784 이하일 경우 그런 결정(H0를 기각하지 않음)을 내리게 될 텐데, H1에 따르면(H1 하에서의 표본평균의 분포를 기준으로 보면) 표본평균이 0.784보다 작을 확률은 위 그림에서 볼 수 있듯 β=0.2946이다. <br></br>\n",
    "따라서1-β=0.7054가 바로 검정력이 되고 귀무가설 H0를 기각하고 대립가설 H1이 옳다고 판단하는 결정이 얼마나 타당한가를 보여주는 지표라고 할 수 있다.\n",
    "\n",
    "\n",
    "귀무가설 H0의 기각이 곧바로 대립가설 H1의 타당성을 보장해주지는 않는다(물론 두 가설이 상호배타적이라면 이야기가 다르지만).<br></br> \n",
    "α를 아무리 작게 한다고 해도 H0를 기각하는 판단의 오류 확률이 줄어들 수 있을 뿐이지, 대립가설이 옳다는 판단(채택)의 타당성을 말해주는 것은 아니다. <br></br>\n",
    "대립가설의 타당성을 보여주는 것은 검정력이며, 가설검정의 실질적인 목적이 대립가설의 가부를 판단하는 것에 있다는 것을 생각하면 정말 중요한 것은 검정력이다. <br></br>\n",
    "검정력은 가설검정의 최종 결론에 대한 신뢰성을 말해준다고 할 수 있다.\n",
    "\n",
    " \n",
    "위의 그림을 통해 알 수 있는 것은 α를 더 작게 만들기 위해서는 기각역이 더 좁아져야 한다는 것(위 예에서는 하한이 더 오른쪽으로 이동해야 한다는 것)을 알 수 있는데, 그렇게 하면 β는 커져야 한다. <br></br>\n",
    "이처럼 표본이 고정된 상태에서는 α와 β는 동시에 줄일 수가 없다.\n",
    "\n",
    "\n",
    "위 예는 대립가설이 단순가설일 때의 경우를 보여주고 있다. <br></br>\n",
    "대립가설이 복합가설로 주어지는 경우에는 위와 같은 과정을 통해서 θ에 따라 β를 구할 수가 있으며, 이것이 바로 검정력 함수가 된다.\n",
    "\n",
    "\n",
    "그렇다면 어떻게 해야 검정력을 최대로 하는 가설검정이 가능할까? <br></br>\n",
    "앞서 보았듯 검정력은 기각역이 주어지면 표본이 늘어나지 않는 이상 자동으로 결정이 되며, 따라서 기각역을 정한다는 것은 곧 검정력을 정한다는 의미이기도 하다.<br></br>\n",
    "검정력을 최대로 만드는 기각역을 '최적기각역'이라 하며 이는 가설검정의 중요한 주제이다.\n",
    "\n",
    "\n",
    "위 그림을 통해서 한 가지 더 알 수 있는 것은 대립가설 H1이 주장하는 모수값이 귀무가설 H0이 주장하는 모수값과 차이가 클 수록 β가 작아진다는 것이다(수리통계학, 213에서 볼 수 있듯 위 경우, H1이 θ = 1.6인 경우에 β는 0.0207이 된다). <br></br>\n",
    "그렇다면 무조건 귀무가설과 극명하게 차이가 나는 가설을 대립가설으로 설정하면 되는 것일까? <br></br>\n",
    "그렇게 무조건 검정력을 높이는 것이 좋은 가설검정이 될 수 있을까? \n",
    "\n",
    "\n",
    "당연히 그러한 가설은 의미가 없다. <br></br>\n",
    "그것은 그저 자신의 주장을 억지로 합리화하려는 가설검정에 불과하기 때문이다.<br></br>\n",
    "가설의 설정은 논리적인 타당성이나 현실성 등 다양한 측면을 고려해서 세심하게 진행되어야 하는 과정이다.\n",
    "\n",
    "\n",
    "[참고서적]\n",
    "\n",
    "송문섭, 허문열, 『수리통계학』, 박영사(2003)\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "[출처 : https://m.blog.naver.com/PostView.nhn?blogId=cto_hwangga&logNo=220479358027&proxyReferer=https%3A%2F%2Fwww.google.co.kr%2F]\n",
    "\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4) missing value가 있을 경우 채워야 할까요? 그 이유는 무엇인가요?\n",
    "\n",
    "A4)\n",
    "\n",
    "<h3>결측값 대체란?</h3>\n",
    "\n",
    "<br></br>\n",
    "결측값(missing value)이 존재할 때, 결측값을 버리고 관측값만 분석하게 되면(listwise deletion) 일반적으로 통계적 편향이 생긴다.<br></br>\n",
    "이에 결측값을 추정한 대체값을 넣어 분석하게 되는데, 이를 결측값대체(imputation) 라 한다.<br></br>\n",
    "\n",
    "<br></br>\n",
    "\n",
    "<h3>결측값 대체의 종류</h3>\n",
    "\n",
    "<br></br>\n",
    "대체의 종류에는 관측치 자체(변수 전체)를 대체하는 unit imputation과 관측치의 일부 변수를 대체하는 item imputation 이 있으며,<br></br>\n",
    "방법론적으로는 크게 single imputation 과 multiple imputation 으로 나뉜다. <br></br>\n",
    "\n",
    "\n",
    "<h4>Single Imputation</h4>\n",
    "\n",
    "\n",
    "<br></br>\n",
    "single imputation은 \n",
    "\n",
    "    1. hot deck\n",
    "\n",
    "    2. mean imputation\n",
    "\n",
    "    3. regression imputation \n",
    "\n",
    "등이 있는데,\n",
    "    <br></br>\n",
    "\n",
    "hot-deck 은 요약하자면 \"가장 많은 걸 넣자\" 내지는 \"안변했을 거야\",<br></br>\n",
    "mean imputation은 이름 그대로 \"평균값을 넣자\", <br></br>\n",
    "regression imputation은 \"다른 있는 값들로 회귀추정을 해서 넣자\" 이다.<br></br>\n",
    "\n",
    "\n",
    "regression imputation에서 결측대체값에 변동이 전혀 없는 fitted value 를 넣다보니 계수추정치에 대한 신뢰도가 과대평가되는 경향이 있다.\n",
    "\n",
    "\n",
    "이를 방지하기 위해 residual 을 추가해준 것을 stochastic regression imputation 이라고 부르며, <br></br>\n",
    "single imputation 중에서는 편향이 제일 적은 결과를 가져온다고 알려져 있다. <br></br>\n",
    "\n",
    "\n",
    "하지만 여전히 과대평가 되는 감이 있는데... <br></br>\n",
    "왜냐하면 결측값과 관측값을 동일 영향도로 만들어준 것에 불과하기 때문이다.<br></br>\n",
    "\n",
    "\n",
    "뭔 말인고 하면,\n",
    "\n",
    "\n",
    "1. 그냥 회귀결측대체 : 결측대체값이 fitted value 그 자체라 변동이 없어 오히려 관측값 '보다' 계수 추정 신뢰도를 높게 평가한다\n",
    "\n",
    "2. 확률적 회귀결측대체 : 결측대체값에 fitted + residual value를 넣어 관측값 '만큼' 계수 추정 신뢰도를 평가한다\n",
    "\n",
    "\n",
    "그런데... 결측대체값이면 관측값보다 더 '약한 신뢰도를 가지게 끔' 만들어야하는 거 아니냔 말이다\n",
    "\n",
    "\n",
    "\n",
    "<br></br>\n",
    "\n",
    "<h4>Multiple Imputation</h4>\n",
    "\n",
    "<br></br>\n",
    "\n",
    "그래서 나온 것이 multiple imputation 이다. \n",
    "\n",
    "\n",
    "single imputation 을 거친 여러개의 데이터 셋을 만들어 평가하므로\n",
    "\n",
    "관측값은 변함이 없어 동일값들이 많이나온 것처럼 평가되어 높은 가중치를 갖는데 비해, \n",
    "\n",
    "결측대체값 들은 만들 때마다 추가해주는 residual로 인한 변동 때문에 관측값보다 상대적으로 '약한 계수 추정 신뢰도' 를 갖게 된다.\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "<img src=\"https://mblogthumb-phinf.pstatic.net/20150620_72/hancury_1434802916220M1ybl_PNG/flow.png?type=w2\">\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "<h3>결측값 대체의 가정</h3>\n",
    "\n",
    "<br></br>\n",
    "\n",
    "우선 결측값대체의 가정(assumption)들은 다음과 같다\n",
    "<br></br>\n",
    "\n",
    "1. MCAR : Missing Completely At Random : 결측여부(missing or not missing)가 무작위\n",
    "\n",
    "2. MAR : Missing At Random : 결측 변수값과 결측여부가 무관. 단, 관측된 타 변수들과 결측여부가 관련있음\n",
    "\n",
    "3. MNAR : Missing Not At Random : 결측 변수값이 결측여부와 관련\n",
    "\n",
    "\n",
    "\n",
    "MCAR는 드물기도 하거니와, 있어도 linewise deletion 에 대한 부작용이 없으니 넘어가고,\n",
    "\n",
    "MAR는 결측여부가 관측된 다른 변수들과 관련있는 경우로서 multiple imputation이 가능하며,\n",
    "\n",
    "MNAR는 결측여부가 결측된 변수의 값 자체과 관련있는 경우다. <br></br>\n",
    "(예를 들어 소득이 낮은 사람이 본인의 소득에 대해 답변하는 것을 기피하는 경우)\n",
    "\n",
    "<br></br>\n",
    "\n",
    "MAR은 결국 간단히 말해 관측 성공 여부와 결측된 변수의 분포는 무관하다는 말이다. \n",
    "\n",
    "따라서 MAR 가정은 관측된 변수들로만 결측값을 추정하는 multiple imputation 에 필수적이다.\n",
    "\n",
    "<img src=\"https://dthumb-phinf.pstatic.net/?src=%22https%3A%2F%2Fssl.pstatic.net%2Fimages.se2%2Fsmedit%2F2015%2F6%2F20%2Fib5a2wnze6ksr8.jpg%22&type=w2\" width=\"500px\">\n",
    "\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "[출처 : https://m.blog.naver.com/hancury/220396495672]<br></br>\n",
    "[출처 : http://blog.naver.com/PostView.nhn?blogId=tjdudwo93&logNo=220978457579&parentCategoryNo=&categoryNo=&viewDate=&isShowPopularPosts=false&from=postView]\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5) 아웃라이어를 판단하는 기준은 무엇인가요?\n",
    "\n",
    "A5)\n",
    "\n",
    "이상치의 판단은 데이터의 시각화를 통해 직관적으로 확인하는 방법이 일반적이다.\n",
    "\n",
    "그러나 데이터의 크기가 커질 경우 일일히 판단하는 작업이 불가능해지기 때문에, \n",
    "\n",
    "두 변수 간 회귀 모형에서 Residual, Studentized residual(혹은 standardized residual), leverage, Cook’s D값을 확인하는 방식으로 아웃라이어를 판별할 수도 있다.\n",
    "\n",
    "Residual의 절대값이 크면서, 동시에 Leverage가 크다면 아웃라이어라고 할 수 있다.\n",
    "\n",
    "Residual의 절대값이 크다고 말할 수 있는 기준은 보통 표준화 잔차가 2 이상일 때를 말한다. (3 이상의 경우 아웃라이어로 확신할 수 있는 수치)\n",
    "\n",
    "Cook’s D값은 Residual과 Leverage를 동시에 고려한 척도로, 해당 값의 전반적인 영향력을 평가한다.\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "[참고 : http://blog.naver.com/PostView.nhn?blogId=libido1014&logNo=120122183719&beginTime=0&jumpingVid=&from=search&redirect=Log&widgetTypeCall=true]\n",
    "\n",
    "[참고 : https://datascienceschool.net/view-notebook/e18a542e4dbd429f8666ccafd1067e7d/]\n",
    "\n",
    "[참고 : http://blog.naver.com/PostView.nhn?blogId=enshs&logNo=221003182320]\n",
    "\n",
    "[참고 : http://www.dodomira.com/2016/10/20/how_to_eda/]\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6) 필요한 표본의 크기를 어떻게 계산합니까?\n",
    "\n",
    "A6) \n",
    "<br></br>\n",
    "\n",
    "표본크기 산출에 고려해야 할 변수는 아래와 같다.\n",
    "<br></br>\n",
    "1. 유의수준 : 제1종 오류(type Ⅰ error)를 허용하는 수준 = “α” 라고 표기\n",
    "2. 검정력 : 제2종 오류(type Ⅰ error, β)를 범하지 않을 확률 = “1- β” 라고 표기\n",
    "3. 효과크기 :독립변수와 종속변수와의 관계의 강도 혹은 크기 / 실험군과 대조군의 평균값의 차이(중재의 효과크기)를 표준편차로 나눈 값\n",
    "<br></br>\n",
    "\n",
    "유의수준을 줄일수록 필요한 표본의 크기는 증가하고, 마찬가지로 검정력을 높일수록 필요한 표본의 크기가 증가한다.<br></br>\n",
    "\n",
    "효과크기가 작을수록 필요한 표본의 크기는 증가한다.\n",
    "\n",
    "[참고 : https://m.blog.naver.com/kkjnn727/220709141689]\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7) Bias를 통제하는 방법은 무엇입니까?\n",
    "\n",
    "A7)\n",
    "\n",
    "$$Bias:=f(x)−E(h(x))$$\n",
    "\n",
    "Bias는 예측값과 실제 값의 차이이다.\n",
    "\n",
    "실험 과정 상 다양한 형태로 bias가 나타날 수 있으며, 이를 통제하는 방법은 그 원인에 따라 다르다.\n",
    "\n",
    "\n",
    "[참고 : https://m.blog.naver.com/PostView.nhn?blogId=beanalogue&logNo=220743698438&categoryNo=144&proxyReferer=]\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8) 로그 함수는 어떤 경우 유용합니까? 사례를 들어 설명해주세요\n",
    "\n",
    "A8) \n",
    "\n",
    "로그 변환을 통해 종속변수와 독립변수의 비선형관계를 선형관계로 표현할 수 있다.<br></br>\n",
    "개별 변수 normalization에 활용할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
